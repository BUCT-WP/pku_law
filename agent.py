import pickle
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime
import json
import os

# è®¾ç½®ç¯å¢ƒå˜é‡æ¥é¿å… tokenizers è­¦å‘Š
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# å¯¼å…¥langchainç›¸å…³ç»„ä»¶
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferWindowMemory
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.schema import BaseMessage, HumanMessage, AIMessage

@dataclass
class ConversationContext:
    """å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†"""
    history: List[Dict[str, str]] = field(default_factory=list)
    current_topic: str = ""
    retrieved_context: List[str] = field(default_factory=list)
    last_query: str = ""
    session_id: str = ""
    
    def add_message(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å†å²è®°å½•"""
        self.history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })
    
    def get_recent_context(self, n: int = 3) -> str:
        """è·å–æœ€è¿‘nè½®å¯¹è¯çš„ä¸Šä¸‹æ–‡"""
        recent = self.history[-n*2:] if len(self.history) >= n*2 else self.history
        context_str = ""
        for msg in recent:
            context_str += f"{msg['role']}: {msg['content']}\n"
        return context_str

class FAISSRetriever:
    """FAISSæ£€ç´¢å™¨"""
    
    def __init__(self, index_path: str = None, metadata_path: str = None):
        self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        
        # å¦‚æœæ²¡æœ‰æä¾›è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if index_path is None:
            index_path = 'law_index.bin'
        if metadata_path is None:
            metadata_path = 'metadata.pkl'
        
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not os.path.isabs(index_path):
            # ç›¸å¯¹äºå½“å‰è„šæœ¬ç›®å½•
            script_dir = os.path.dirname(os.path.abspath(__file__))
            index_path = os.path.join(script_dir, index_path)
        
        if not os.path.isabs(metadata_path):
            # ç›¸å¯¹äºå½“å‰è„šæœ¬ç›®å½•
            script_dir = os.path.dirname(os.path.abspath(__file__))
            metadata_path = os.path.join(script_dir, metadata_path)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(index_path):
            raise FileNotFoundError(f"FAISS index file not found: {index_path}")
        if not os.path.exists(metadata_path):
            raise FileNotFoundError(f"Metadata file not found: {metadata_path}")
        
        self.index = faiss.read_index(index_path)
        
        with open(metadata_path, 'rb') as f:
            self.metadata = pickle.load(f)
    
    def search(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """æœç´¢ç›¸å…³æ³•æ¡"""
        query_vec = self.model.encode([query])
        distances, indices = self.index.search(np.array(query_vec), k)
        
        results = []
        for idx, i in enumerate(indices[0]):
            if i < len(self.metadata):
                results.append({
                    'content': self.metadata[i]['content'],
                    'filename': self.metadata[i]['filename'],
                    'score': 1 / (1 + distances[0][idx]),
                    'distance': distances[0][idx]
                })
        
        return results

class RetrievalAgent:
    """æ£€ç´¢Agent"""
    
    def __init__(self, retriever: FAISSRetriever):
        self.retriever = retriever
    
    def retrieve_relevant_laws(self, query: str, context: ConversationContext) -> str:
        """æ£€ç´¢ç›¸å…³æ³•æ¡"""
        # ç»“åˆä¸Šä¸‹æ–‡ä¼˜åŒ–æ£€ç´¢æŸ¥è¯¢
        enhanced_query = query
        if context.current_topic:
            enhanced_query = f"{context.current_topic} {query}"
        
        results = self.retriever.search(enhanced_query, k=3)
        
        # æ ¼å¼åŒ–æ£€ç´¢ç»“æœ
        formatted_results = []
        for result in results:
            formatted_results.append(f"æ³•æ¡å†…å®¹: {result['content'][:500]}...")
        
        # æ›´æ–°ä¸Šä¸‹æ–‡
        context.retrieved_context = [r['content'] for r in results]
        context.last_query = query
        
        return "\n\n".join(formatted_results)
    
    def display_search_results(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """å±•ç¤ºæ£€ç´¢ç»“æœçš„è¯¦ç»†ä¿¡æ¯"""
        results = self.retriever.search(query, k=k)
        
        print(f"\nğŸ“‹ æ£€ç´¢ç»“æœ (å…±æ‰¾åˆ° {len(results)} æ¡ç›¸å…³æ³•æ¡):")
        print("=" * 80)
        
        for i, result in enumerate(results, 1):
            print(f"\nã€æ³•æ¡ {i}ã€‘")
            print(f"ğŸ“– æ¥æºæ–‡ä»¶: {result['filename']}")
            print(f"ğŸ¯ ç›¸å…³åº¦è¯„åˆ†: {result['score']:.4f}")
            print(f"ğŸ“„ å†…å®¹:")
            print("-" * 40)
            print(result['content'])
            print("-" * 40)
        
        return results

class QAAgent:
    """é—®ç­”Agent"""
    
    def __init__(self, llm):
        self.llm = llm
        self.qa_prompt = PromptTemplate(
            input_variables=["context", "history", "question"],
            template="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ³•å¾‹å’¨è¯¢åŠ©æ‰‹ã€‚åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ï¼š

å¯¹è¯å†å²ï¼š
{history}

ç›¸å…³æ³•æ¡ï¼š
{context}

é—®é¢˜ï¼š{question}

è¯·æ ¹æ®ç›¸å…³æ³•æ¡ï¼Œç»“åˆå¯¹è¯å†å²ï¼Œç»™å‡ºå‡†ç¡®ã€ä¸“ä¸šçš„æ³•å¾‹å»ºè®®ã€‚å¦‚æœæ³•æ¡ä¸è¶³ä»¥å®Œå…¨å›ç­”é—®é¢˜ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚
ä¸è¦ä½¿ç”¨mdæ ¼å¼ï¼Œçº¯æ–‡æœ¬è¾“å‡º
å›ç­”ï¼š"""
        )
        self.qa_chain = LLMChain(llm=self.llm, prompt=self.qa_prompt)
    
    def answer_question(self, question: str, context: ConversationContext, retrieved_context: str) -> str:
        """å›ç­”æ³•å¾‹é—®é¢˜"""
        history = context.get_recent_context(3)
        print(retrieved_context)
        response = self.qa_chain.invoke({
            "context": retrieved_context,
            "history": history,
            "question": question
        })
        
        return response["text"]

class SummaryAgent:
    """æ€»ç»“Agent"""
    
    def __init__(self, llm):
        self.llm = llm
        self.summary_prompt = PromptTemplate(
            input_variables=["conversation", "key_points"],
            template="""è¯·æ€»ç»“ä»¥ä¸‹æ³•å¾‹å’¨è¯¢å¯¹è¯çš„è¦ç‚¹ï¼š

å¯¹è¯å†…å®¹ï¼š
{conversation}

é‡è¦æ³•æ¡ï¼š
{key_points}

è¯·æä¾›ç®€æ´çš„æ€»ç»“ï¼ŒåŒ…æ‹¬ï¼š
1. å’¨è¯¢çš„ä¸»è¦æ³•å¾‹é—®é¢˜
2. æ¶‰åŠçš„ç›¸å…³æ³•æ¡
3. ç»™å‡ºçš„å»ºè®®è¦ç‚¹

æ€»ç»“ï¼š"""
        )
        self.summary_chain = LLMChain(llm=self.llm, prompt=self.summary_prompt)
    
    def summarize_conversation(self, context: ConversationContext) -> str:
        """æ€»ç»“å¯¹è¯å†…å®¹"""
        conversation = "\n".join([
            f"{msg['role']}: {msg['content']}" 
            for msg in context.history
        ])
        
        key_points = "\n".join(context.retrieved_context[:3])
        
        summary = self.summary_chain.invoke({
            "conversation": conversation,
            "key_points": key_points
        })
        
        return summary["text"]

class LegalConsultationSystem:
    """æ³•å¾‹å’¨è¯¢ç³»ç»Ÿä¸»ç±»"""
    
    def _get_data_file_path(self, relative_path: str) -> str:
        """è·å–æ•°æ®æ–‡ä»¶çš„ç»å¯¹è·¯å¾„"""
        # å¦‚æœå·²ç»æ˜¯ç»å¯¹è·¯å¾„ï¼Œç›´æ¥è¿”å›
        if os.path.isabs(relative_path):
            return relative_path
        
        # å¦åˆ™ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
        # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆagent.pyæ‰€åœ¨ç›®å½•ï¼‰
        current_dir = os.path.dirname(os.path.abspath(__file__))
        # é¡¹ç›®æ ¹ç›®å½•å°±æ˜¯å½“å‰ç›®å½•
        project_root = current_dir
        
        return os.path.join(project_root, relative_path)
    
    def __init__(self, openai_api_key: str, index_path: str = None, metadata_path: str = None):
        # åˆå§‹åŒ–LLM
        base_url = os.getenv("OPENAI_BASE_URL", "https://api.siliconflow.cn/v1")
        model_name = os.getenv("OPENAI_MODEL", "Tongyi-Zhiwen/QwenLong-L1-32B")
        
        self.llm = ChatOpenAI(
            openai_api_key=openai_api_key,
            base_url=base_url,
            model_name=model_name,
            temperature=0.1,
            streaming=True,
            callbacks=[StreamingStdOutCallbackHandler()]
        )
        
        # è·å–æ•°æ®æ–‡ä»¶è·¯å¾„
        if index_path is None:
            index_path = self._get_data_file_path(os.getenv("FAISS_INDEX_PATH", "law_index.bin"))
        if metadata_path is None:
            metadata_path = self._get_data_file_path(os.getenv("METADATA_PATH", "metadata.pkl"))
        
        # åˆå§‹åŒ–å„ä¸ªAgent
        self.retriever = FAISSRetriever(index_path, metadata_path)
        self.retrieval_agent = RetrievalAgent(self.retriever)
        self.qa_agent = QAAgent(self.llm)
        self.summary_agent = SummaryAgent(self.llm)
        
        # ä¸Šä¸‹æ–‡ç®¡ç†
        self.context = ConversationContext()
        
        # è®°å¿†ç®¡ç†
        self.memory = ConversationBufferWindowMemory(
            k=10,
            return_messages=True,
            memory_key="chat_history"
        )
    
    def process_query(self, query: str) -> str:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
        try:
            # 1. æ£€ç´¢ç›¸å…³æ³•æ¡
            print("ğŸ” æ­£åœ¨æ£€ç´¢ç›¸å…³æ³•æ¡...")
            retrieved_context = self.retrieval_agent.retrieve_relevant_laws(query, self.context)
            
            # 2. ç”Ÿæˆå›ç­”
            print("ğŸ¤– æ­£åœ¨ç”Ÿæˆæ³•å¾‹å»ºè®®...")
            answer = self.qa_agent.answer_question(query, self.context, retrieved_context)
            
            # 3. æ›´æ–°ä¸Šä¸‹æ–‡
            self.context.add_message("user", query)
            self.context.add_message("assistant", answer)
            
            # 4. æ›´æ–°è®°å¿†
            self.memory.save_context({"input": query}, {"output": answer})
            
            return answer
            
        except Exception as e:
            error_msg = f"å¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            print(f"âŒ {error_msg}")
            return error_msg
    
    def search_and_display(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """æœç´¢å¹¶å±•ç¤ºæ³•å¾‹æ–‡æ¡£æ£€ç´¢ç»“æœ"""
        return self.retrieval_agent.display_search_results(query, k)
    
    def process_query_with_display(self, query: str, show_results: bool = True) -> str:
        """å¤„ç†æŸ¥è¯¢å¹¶å¯é€‰æ‹©å±•ç¤ºæ£€ç´¢ç»“æœ"""
        try:
            # 1. æ£€ç´¢å¹¶å±•ç¤ºç›¸å…³æ³•æ¡
            print("ğŸ” æ­£åœ¨æ£€ç´¢ç›¸å…³æ³•æ¡...")
            if show_results:
                self.search_and_display(query, k=3)
            
            retrieved_context = self.retrieval_agent.retrieve_relevant_laws(query, self.context)
            
            # 2. ç”Ÿæˆå›ç­”
            print("ğŸ¤– æ­£åœ¨ç”Ÿæˆæ³•å¾‹å»ºè®®...")
            answer = self.qa_agent.answer_question(query, self.context, retrieved_context)
            
            # 3. æ›´æ–°ä¸Šä¸‹æ–‡
            self.context.add_message("user", query)
            self.context.add_message("assistant", answer)
            
            # 4. æ›´æ–°è®°å¿†
            self.memory.save_context({"input": query}, {"output": answer})
            
            return answer
            
        except Exception as e:
            error_msg = f"å¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            print(f"âŒ {error_msg}")
            return error_msg
    
    def get_conversation_summary(self) -> str:
        """è·å–å¯¹è¯æ€»ç»“"""
        if not self.context.history:
            return "æš‚æ— å¯¹è¯è®°å½•"
        
        return self.summary_agent.summarize_conversation(self.context)
    
    def reset_context(self):
        """é‡ç½®å¯¹è¯ä¸Šä¸‹æ–‡"""
        self.context = ConversationContext()
        self.memory.clear()
    
    def save_session(self, filepath: str):
        """ä¿å­˜ä¼šè¯"""
        session_data = {
            "context": self.context.__dict__,
            "timestamp": datetime.now().isoformat()
        }
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(session_data, f, ensure_ascii=False, indent=2)
    
    def load_session(self, filepath: str):
        """åŠ è½½ä¼šè¯"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                session_data = json.load(f)
            
            # æ¢å¤ä¸Šä¸‹æ–‡
            context_dict = session_data["context"]
            self.context = ConversationContext(**context_dict)
            
            # æ¢å¤è®°å¿†
            for msg in self.context.history:
                if msg["role"] == "user":
                    user_msg = msg["content"]
                elif msg["role"] == "assistant":
                    assistant_msg = msg["content"]
                    self.memory.save_context({"input": user_msg}, {"output": assistant_msg})
                    
        except Exception as e:
            print(f"åŠ è½½ä¼šè¯å¤±è´¥: {str(e)}")

